{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gretel Transformers Walkthrough\n",
    "\n",
    "Welcome to the Gretel Transformers walkthrough! In this tutorial we will take you through the process of creating a data pipeline to apply a variety of transformations to your data.\n",
    "\n",
    "This tutorial assumes you have already uploaded data to Gretel.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "- If using Google Colab, we recommend you change to a GPU runtime.\n",
    "\n",
    "- Input your Gretel URI String\n",
    "\n",
    "- Create your Gretel Synthetic Configuration Template\n",
    "  - See [our documentation](https://gretel-synthetics.readthedocs.io/en/stable/api/config.html) for additional config options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import getpass\n",
    "import os\n",
    "import pprint\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=3)\n",
    "gretel_uri = os.getenv(\"GRETEL_URI\") or getpass.getpass(\"Your Gretel URI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Gretel Project Instance\n",
    "\n",
    "In the code below, we will utilize the gretel-client to create an instance of a project that will be used to syntesize data from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "gretel_synthetics_deps"
   },
   "outputs": [],
   "source": [
    "# !pip install gretel-client --upgrade\n",
    "# !pip install \"gretel-client[fpe]==0.7.0.rc2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "gretel_synthetics_boilerplate"
   },
   "outputs": [],
   "source": [
    "from gretel_client import project_from_uri\n",
    "from gretel_client.demo_helpers import RandomTransformerPipeline\n",
    "\n",
    "project = project_from_uri(gretel_uri)\n",
    "random_pipeline = RandomTransformerPipeline(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see how many records we've ingested and how many fields we've discovered, just to show the\n",
    "# project is active.\n",
    "print(f'Total Records Received: {project.record_count}\\n')\n",
    "print(f'Total Fields Discovered: {project.field_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Entity types to transform\n",
    "\n",
    "Gretel supports a range of transformations for numeric and string data.  Below we leverage methods of the Project class to find some representative fields and apply sample transformers to them.  First, let's go looking for some common entity types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pipeline.detect_entities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing identifying entities with string transformations\n",
    "\n",
    "Now we start building up our pipeline.  We will define transformers and then specify the fields they act on with a data path.  We will build up a list of these to make our data pipeline.  Let's start with some tranformations we might want to do on identifiers -- redact them, encrypt them, fake them or just drop them.  We will choose at random.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pipeline.build_anonymizing_transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rounding numeric latitudes and longitudes\n",
    "\n",
    "Let's keep going.  We will use some of the same transformers for string locations.  For numeric, let's round the values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pipeline.build_location_transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifting date values\n",
    "\n",
    "Finally, in addition to the transformers above, you can also shift dates.  Here we keep it simple, but there are options to modify the shift based on another input field and you can specify other formats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_pipeline.build_date_shift_transforms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pipeline in action, er, book with a pipeline animal\n",
    "\n",
    "Now we can create our data pipeline.  We will run some sample records through it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_client.transformers import DataTransformPipeline, DataRestorePipeline, DataPath\n",
    "\n",
    "# Add one last catch all.  If you have a noisy data set you could make this another DropConfig. This will pass\n",
    "# any un-transformed field through the pipeline unchanged.\n",
    "random_pipeline.data_paths.append(DataPath(input=\"*\"))\n",
    "\n",
    "# Make the pipe\n",
    "pipe = DataTransformPipeline(random_pipeline.data_paths)\n",
    "\n",
    "# Bonus trick for the end\n",
    "restore_pipe = DataRestorePipeline(random_pipeline.data_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample records from your project\n",
    "records = project.sample()\n",
    "pp.pprint(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those same records transformed\n",
    "transformed_records = []\n",
    "for rec in records:\n",
    "    transformed_records.append(pipe.transform_record(rec))\n",
    "pp.pprint(transformed_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover anything that used the SECRET\n",
    "restored_records = [restore_pipe.transform_record(rec) for rec in transformed_records]\n",
    "print(restored_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
