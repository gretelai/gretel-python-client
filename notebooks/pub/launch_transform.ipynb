{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gretel Transformers Walkthrough\n",
    "\n",
    "Welcome to the Gretel Transformers walkthrough! In this tutorial we will take you through the process of creating a data pipeline to apply a variety of transformations to your data.\n",
    "\n",
    "This tutorial assumes you have already uploaded data to Gretel.\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "- If using Google Colab, we recommend you change to a GPU runtime.\n",
    "\n",
    "- Input your Gretel URI String\n",
    "\n",
    "- Create your Gretel Synthetic Configuration Template\n",
    "  - See [our documentation](https://gretel-synthetics.readthedocs.io/en/stable/api/config.html) for additional config options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import getpass\n",
    "import os\n",
    "\n",
    "gretel_uri = os.getenv(\"GRETEL_URI\") or getpass.getpass(\"Your Gretel URI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Gretel Project Instance\n",
    "\n",
    "In the code below, we will utilize the gretel-client to create an instance of a project that will be used to syntesize data from. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "gretel_synthetics_deps"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# mark: cell_id=gretel_client_deps\n",
    "\n",
    "!pip install gretel-client --upgrade\n",
    "!pip install \"gretel-client[fpe]==0.7.0.rc2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_id": "gretel_synthetics_boilerplate"
   },
   "outputs": [],
   "source": [
    "# mark: cell_id=gretel_client_boilerplate\n",
    "from gretel_client import project_from_uri\n",
    "\n",
    "project = project_from_uri(gretel_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can see how many records we've ingested and how many fields we've discovered, just to show the\n",
    "# project is active.\n",
    "print(f'Total Records Received: {project.record_count}\\n')\n",
    "print(f'Total Fields Discovered: {project.field_count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Entity types to transform\n",
    "\n",
    "Gretel supports a range of transformations for numeric and string data.  Below we leverage methods of the Project class to find some representative fields and apply sample transformers to them.  First, let's go looking for some common entity types.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See all the entity types detected in this project.\n",
    "entity_types = [d['entity'] for d in project.entities]\n",
    "print(f\"Detected entity types: {entity_types}\")\n",
    "\n",
    "# Let's look for some identifiers... We will filter these examples against what we actually found.\n",
    "identifying_entities = [\"person_name\", \"email_address\", \"ip_address\", \"uuid\"]\n",
    "identifying_entities = [e for e in identifying_entities if e in entity_types]\n",
    "\n",
    "person_name_fields = [d['field'] for d in project.get_field_details(entity=\"person_name\")]\n",
    "\n",
    "# And some places, both strings and numbers if we can...\n",
    "location_entities = [\"city\", \"us_zip_code\", \"latitude\", \"longitude\"]\n",
    "location_entities = [e for e in location_entities if e in entity_types]\n",
    "\n",
    "# Everyone loves working with dates.\n",
    "time_entities = [\"date\", \"datetime\"]\n",
    "time_entities = [e for e in time_entities if e in entity_types]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing identifying entities with string transformations\n",
    "\n",
    "Now we start building up our pipeline.  We will define transformers and then specify the fields they act on with a data path.  We will build up a list of these to make our data pipeline.  Let's start with some tranformations we might want to do on identifiers -- redact them, encrypt them, fake them or just drop them.  We will choose at random.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from gretel_client.transformers import (\n",
    "    DropConfig,\n",
    "    FakeConstantConfig,\n",
    "    FpeStringConfig,\n",
    "    RedactWithCharConfig,\n",
    "    RedactWithLabelConfig,\n",
    "    RedactWithStringConfig,\n",
    "    StringMask,\n",
    "    DataPath,\n",
    "    DataTransformPipeline,\n",
    "    DataRestorePipeline\n",
    ")\n",
    "from gretel_client.transformers.fakers import FAKER_MAP\n",
    "\n",
    "# Define a seed value to use for faker transformations to ensure consistent output\n",
    "SEED = 6251\n",
    "\n",
    "# Define a secret for format preserving encryption.  \n",
    "# \"Do not store it plain text in github\" boilerplate goes here :)\n",
    "SECRET = \"2B7E151628AED2A6ABF7158809CF4F3CEF4359D8D580AA4F7F036D6F04FC6A94\"\n",
    "\n",
    "data_paths = []\n",
    "\n",
    "for entity in identifying_entities:\n",
    "    # Get all the project fields tagged as this entity type\n",
    "    entity_fields = [d['field'] for d in project.get_field_details(entity=entity)]\n",
    "    for field in entity_fields:\n",
    "        dice_roll = random.randint(1,6)\n",
    "        xf = []\n",
    "        if dice_roll == 1:\n",
    "            print(f\"Dropping field {field}\")\n",
    "            xf = [DropConfig()]\n",
    "        if dice_roll == 2:\n",
    "            print(f\"Faking field {field}\")\n",
    "            xf = [FakeConstantConfig(seed=SEED, fake_method=FAKER_MAP.get(entity))]\n",
    "        if dice_roll == 3:\n",
    "            print(f\"Encrypting field {field}\")\n",
    "            # radix 62 will encrypt alphanumeric but no special characters\n",
    "            xf = [FpeStringConfig(secret=SECRET, radix=62)]\n",
    "        if dice_roll == 4:\n",
    "            print(f\"Character redacting field {field}\")\n",
    "            # Use a fancier mask for emails\n",
    "            if entity == \"email_address\":\n",
    "                xf = [RedactWithCharConfig(\n",
    "                        char=\"X\",\n",
    "                        mask=[StringMask(start_pos=3, mask_until=\"@\"), \n",
    "                            StringMask(mask_after=\"@\", mask_until=\".\", greedy=True)])]\n",
    "            else:\n",
    "                xf = [RedactWithCharConfig(\"#\", mask=[StringMask(start_pos=3)])]\n",
    "        if dice_roll == 5:\n",
    "            print(f\"Label redacting field {field}\")\n",
    "            xf = [RedactWithLabelConfig(labels=[entity])]\n",
    "        if dice_roll == 6:\n",
    "            print(f\"String redacting field {field}\")\n",
    "            xf = [RedactWithStringConfig(string=\"CLASSIFIED\")]\n",
    "        data_paths.append(DataPath(input=field, xforms=xf))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rounding numeric latitudes and longitudes\n",
    "\n",
    "Let's keep going.  We will use some of the same transformers for string locations.  For numeric, let's round the values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_client.transformers import (\n",
    "    bucket_creation_params_to_list,\n",
    "    BucketCreationParams,\n",
    "    BucketConfig\n",
    ")\n",
    "\n",
    "for entity in location_entities:\n",
    "    # Get all the project fields tagged as this entity type\n",
    "    entity_fields = [d['field'] for d in project.get_field_details(entity=entity)]\n",
    "    for field in entity_fields:\n",
    "        xf = []\n",
    "        if entity in [\"city\", \"us_zip_code\"]:\n",
    "            print(f\"Faking field {field}\")\n",
    "            xf = [FakeConstantConfig(seed=SEED, fake_method=FAKER_MAP[entity])]\n",
    "        else:\n",
    "            print(f\"Rounding field {field}\")\n",
    "            min_max_width_tuple = BucketCreationParams(-180.0, 180.0, 0.1)\n",
    "            buckets = bucket_creation_params_to_list(min_max_width_tuple)\n",
    "            xf = [BucketConfig(buckets=buckets)]\n",
    "        data_paths.append(DataPath(input=field, xforms=xf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shifting date values\n",
    "\n",
    "Finally, in addition to the transformers above, you can also shift dates.  Here we keep it simple, but there are options to modify the shift based on another input field and you can specify other formats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gretel_client.transformers import (\n",
    "    DateShiftConfig\n",
    ")\n",
    "\n",
    "for entity in location_entities:\n",
    "    # Get all the project fields tagged as this entity type\n",
    "    entity_fields = [d['field'] for d in project.get_field_details(entity=entity)]\n",
    "    for field in entity_fields:\n",
    "        print(f\"Date shifting field {field}\")\n",
    "        xf = [DateShiftConfig(secret=SECRET, lower_range_days=-10, upper_range_days=25)]\n",
    "        data_paths.append(DataPath(input=field, xforms=xf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pipeline in action, er, book with a pipeline animal\n",
    "\n",
    "Now we can create our data pipeline.  We will run some sample records through it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add one last catch all\n",
    "# data_paths.append(DataPath(input=\"*\"))\n",
    "# Make the pipe\n",
    "pipe = DataTransformPipeline(data_paths)\n",
    "# Bonus trick for the end\n",
    "restore_pipe = DataRestorePipeline(data_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample records from your project\n",
    "records = project.sample()\n",
    "print(records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those same records transformed\n",
    "transformed_records = [pipe.transform_record(rec) for rec in records]\n",
    "print(transformed_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recover anything that used the SECRET\n",
    "restored_records = [restore_pipe.transform_record(rec) for rec in transformed_records]\n",
    "print(restored_records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
